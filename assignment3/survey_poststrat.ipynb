{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4209d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6636e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegressionType = sklearn.linear_model._logistic.LogisticRegression\n",
    "LabelEncoderType = sklearn.preprocessing._label.LabelEncoder\n",
    "EncoderType = sklearn.pipeline.Pipeline\n",
    "\n",
    "REGION_COLUMNS = ['New England',\n",
    "                  'Middle Atlantic',\n",
    "                  'East North Central',\n",
    "                  'West North Central',\n",
    "                  'South Atlantic',\n",
    "                  'East South Central',\n",
    "                  'West South Central',\n",
    "                  'Mountain',\n",
    "                  'Pacific']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86cb3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in census data\n",
    "f = open('census_data.json')\n",
    "census_data = json.load(f)\n",
    "census_data = [sublist[:-1] for sublist in census_data]\n",
    "census_df = pd.DataFrame(census_data)\n",
    "census_df = census_df.transpose()\n",
    "column = ['Demographics']\n",
    "column.extend(REGION_COLUMNS)\n",
    "census_df.columns = column\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c88436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map census categories to survey categories\n",
    "s_to_c_mappings = {\n",
    "    'Gender': {'Male': '1', 'Female': '2'},\n",
    "    'Age': {'> 60': '1', '45-60': '2', '30-44': '3', '18-29': '4'},\n",
    "    'Household Income': {'$150,000+': '1', '$100,000 - $149,999': '2', '$50,000 - $99,999': '3', '$25,000 - $49,999': '4', '$0 - $24,999': '5'},\n",
    "    'Education': {'Graduate degree': '1', 'Bachelor degree': '2', 'Some college or Associate degree': '3', 'High school degree': '4', 'Less than high school degree': '5'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312a09cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine survey data\n",
    "og_survey_df = pd.read_csv('comma-survey.csv', index_col='RespondentID')\n",
    "new_survey_df = pd.read_csv('new_comma_survey.csv', index_col='RespondentID')\n",
    "survey_df = pd.concat([og_survey_df, new_survey_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77ba548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract question and demographics column names\n",
    "question_cols = list(survey_df.columns)[:7]\n",
    "demographic_cols = list(survey_df.columns)[7:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc112f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where at least one of the sbustansive questions were not answered\n",
    "survey_df = survey_df.dropna(axis=0, subset=question_cols)\n",
    "# Drop rows where all the demographic questions were unanswered\n",
    "survey_df = survey_df.dropna(axis=0, how='all', subset=demographic_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ed58432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode demographic responses\n",
    "demographics = survey_df[demographic_cols].to_numpy()\n",
    "# Define the ordinal features pipeline\n",
    "enc = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', missing_values=np.nan, add_indicator=True)),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "enc.fit(demographics)\n",
    "X_demographics = enc.transform(demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11b8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit label encoders\n",
    "labelEncoders = [LabelEncoder() for i in range(len(question_cols))]\n",
    "for idx, q in enumerate(question_cols):\n",
    "    y_vals = survey_df[q].to_numpy()\n",
    "    labelEncoders[idx].fit(y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c087ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "models = [LogisticRegression(multi_class='multinomial', max_iter=1000, fit_intercept=False) for i in range(len(question_cols))]\n",
    "for idx, q in enumerate(question_cols):\n",
    "    y_vals = survey_df[q].to_numpy()\n",
    "    Y_vals = labelEncoders[idx].transform(y_vals)\n",
    "    model = models[idx].fit(X_demographics, Y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "061d2429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all demographic combinations, dropping nans\n",
    "demographic_options = []\n",
    "for d in demographic_cols:\n",
    "    demographic_options.append(survey_df[d].unique())\n",
    "unique_combinations = list(itertools.product(*demographic_options))\n",
    "unique_combinations = [i for i in unique_combinations if np.nan not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc826bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: In your opinion, which sentence is more gramatically correct?\n",
      "It's important for a person to be honest, kind and loyal. : 45.28%\n",
      "It's important for a person to be honest, kind, and loyal. : 54.72%\n",
      "\n",
      "Q1: Prior to reading about it above, had you heard of the serial (or Oxford) comma?\n",
      "No : 46.71%\n",
      "Yes : 53.29%\n",
      "\n",
      "Q2: How much, if at all, do you care about the use (or lack thereof) of the serial (or Oxford) comma in grammar?\n",
      "A lot : 25.92%\n",
      "Not at all : 12.94%\n",
      "Not much : 25.35%\n",
      "Some : 35.79%\n",
      "\n",
      "Q3: How would you write the following sentence?\n",
      "Some experts say it's important to drink milk, but the data are inconclusive. : 18.83%\n",
      "Some experts say it's important to drink milk, but the data is inconclusive. : 81.17%\n",
      "\n",
      "Q4: When faced with using the word \"data\", have you ever spent time considering if the word was a singular or plural noun?\n",
      "No : 54.76%\n",
      "Yes : 45.24%\n",
      "\n",
      "Q5: How much, if at all, do you care about the debate over the use of the word \"data\" as a singluar or plural noun?\n",
      "A lot : 10.54%\n",
      "Not at all : 20.25%\n",
      "Not much : 39.74%\n",
      "Some : 29.47%\n",
      "\n",
      "Q6: In your opinion, how important or unimportant is proper use of grammar?\n",
      "Neither important nor unimportant (neutral) : 4.02%\n",
      "Somewhat important : 31.78%\n",
      "Somewhat unimportant : 0.95%\n",
      "Very important : 62.81%\n",
      "Very unimportant : 0.43%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of running sums\n",
    "running_sums = {\n",
    "    0: {0: 0.0, 1: 0.0},\n",
    "    1: {0: 0.0, 1: 0.0},\n",
    "    2: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
    "    3: {0: 0.0, 1: 0.0},\n",
    "    4: {0: 0.0, 1: 0.0},\n",
    "    5: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0},\n",
    "    6: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}\n",
    "}\n",
    "# Calculate the predicted outcome\n",
    "total_population = 0\n",
    "for combo in unique_combinations:\n",
    "    # Get the corresponding count from Census data\n",
    "    gender, age, income, education = combo\n",
    "    x_vals = enc.transform([combo])\n",
    "    census_mapping = {\n",
    "        'SEX': s_to_c_mappings['Gender'][gender],\n",
    "        'AGEP_RC2': s_to_c_mappings['Age'][age],\n",
    "        'SCHL_RC2': s_to_c_mappings['Household Income'][income],\n",
    "        'HINCP_RC2': s_to_c_mappings['Education'][education]\n",
    "    }\n",
    "    row = census_df[REGION_COLUMNS].loc[census_df['Demographics'] == census_mapping]\n",
    "    deographic_total = row.sum(axis=1).values[0]\n",
    "    total_population += deographic_total\n",
    "    # For every substansive question\n",
    "    for q_idx in range(len(question_cols)):\n",
    "        # Get the probability predictions\n",
    "        y_prob = models[q_idx].predict_proba(x_vals)[0]\n",
    "        for a_idx in range(len(y_prob)):\n",
    "            running_sums[q_idx][a_idx] += y_prob[a_idx] * deographic_total\n",
    "tot_pop_for_percent = total_population / 100\n",
    "for q_idx, answer_probs in running_sums.items():\n",
    "    print('Q' + str(q_idx) + ':', question_cols[q_idx])\n",
    "    for a_idx, r_sum in answer_probs.items():\n",
    "        answer_options = labelEncoders[q_idx].inverse_transform(models[q_idx].classes_)\n",
    "        print(answer_options[a_idx], ':', '{:.2f}%'.format(r_sum / tot_pop_for_percent))\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73db109",
   "metadata": {},
   "source": [
    "for every combination in unique combinations,\n",
    "  we get the corresponding count from Census data\n",
    "  for every substansive question:\n",
    "    we get the probability predictions from our models\n",
    "    we multiply the Census count by probability predictions and add these to the corresponding running sums\n",
    "\n",
    "for every combination in Census data,\n",
    "  we sum up the counts to get a total Census count\n",
    "  \n",
    "for every running sum:\n",
    "  divide by total to get population fraction answering like this\n",
    "  \n",
    "How to store the running sums:\n",
    "  Nested dictionary {substansive_q_number: {outcome_1: running_sum1, ..., outcome_n: running_sumn}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ff117",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d9e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
